{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is to scrape public websites to get published population details of countries part of the analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    type(soup)\n",
    "    title = soup.title\n",
    "    text = soup.get_text()\n",
    "    rows = soup.find_all('tr')\n",
    "    list_rows = []\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        str_cells = str(cells)\n",
    "        clean2 = (re.sub(r'[^\\x00-\\x7f]', '', (re.sub(r'\\[.\\]', '', (re.sub(r'(?<=\\d),(?=\\d)', '', (re.sub('\\n', '', (re.sub(r'<.*?>', '', str_cells))))))))))\n",
    "        list_rows.append(clean2)\n",
    "        type(clean2)\n",
    "    df = pd.DataFrame(list_rows)\n",
    "    df1 = df[0].str.split(',', expand=True)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape 1st URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
    "df1 = scrape_url(url)\n",
    "df1.columns = [ 'rank', 'country', 'population', 'date1', 'date2', '%population', 'source','temp']\n",
    "df1['rank'] = df1['rank'].str.replace('[','')\n",
    "df1['country'] = df1['country'].str.replace(r\"\\[.*\\]\",\"\").str.replace(' ', \"\")\n",
    "df1['date'] = df1['date1'] +  df1['date2']\n",
    "df1 = df1.iloc[1:-13,]\n",
    "df1 = df1.set_index('rank')\n",
    "df1 = df1.drop(['temp', 'date1', 'date2', 'source'], axis=1)\n",
    "df1.to_csv('./countries_population.csv', header=True, sep=',')\n",
    "report = pd.read_csv('./model_summary.csv')\n",
    "merge1 = pd.merge(report,df1, how='left', on = 'country')\n",
    "\n",
    "#scrape 2nd URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_by_population_growth_rate\"\n",
    "df2 = scrape_url(url)\n",
    "df2 = df2.iloc[244:483,]\n",
    "cols = [x for x in range(7,1922)]\n",
    "df2 = df2.drop(df2.columns[cols],axis=1)\n",
    "df2.columns =['country', '2009', '2012', '2014', '2005-2010', '2010-2015', '2015-2020']\n",
    "df2['country'] = df2['country'].str.replace(r\"\\[.*\\]\",\"\").str.replace(' ', \"\").str.replace('[','')\n",
    "df2['2015-2020'] = df2['2015-2020'].str.replace(' ', \"\").str.replace(']', '')\n",
    "df2 = df2.set_index('country')\n",
    "df2.to_csv('./countries_population_change.csv', header=True, sep=',')\n",
    "summary = pd.merge(merge1, df2, how='left', on = 'country')\n",
    "summary.to_csv('./report_summary.csv', header=True, index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
